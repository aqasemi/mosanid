{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain.document_loaders import (\n",
    "    Docx2txtLoader,\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    ")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "source_directory = '/docs'\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "LOADER_MAPPING = {\n",
    "    \".docx\": (Docx2txtLoader, {}),\n",
    "    \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".html\": (UnstructuredHTMLLoader, {}),\n",
    "    \".md\": (UnstructuredMarkdownLoader, {}),\n",
    "    \".pdf\": (PyPDFLoader, {}),\n",
    "    # \".ppt\": (UnstructuredPowerPointLoader, {'mode': 'elements', 'strategy': 'fast'}),\n",
    "    # \".pptx\": (UnstructuredPowerPointLoader, {'mode': 'elements', 'strategy': 'fast'}),\n",
    "    \".txt\": (TextLoader, {\"encoding\": \"utf8\"}),\n",
    "}\n",
    "\n",
    "\n",
    "def load_single_document(file_path: str) -> List[Document]:\n",
    "    ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n",
    "    # TODO: if no extension found, parse metadata to determine file type\n",
    "    if ext in LOADER_MAPPING:\n",
    "        loader_class, loader_args = LOADER_MAPPING[ext]\n",
    "        loader: BaseLoader = loader_class(file_path, **loader_args)\n",
    "        return loader.load()\n",
    "\n",
    "    raise ValueError(f\"Unsupported file extension '{ext}'\")\n",
    "\n",
    "def load_documents(source_dir: str, ignored_files: List[str] = []) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads all documents from the source documents directory, ignoring specified files\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for ext in LOADER_MAPPING:\n",
    "        file = glob.glob(os.path.join(source_dir, f\"**/*{ext}\"), recursive=True)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                next(map(file.remove, (f for ignored_file in ignored_files for f in file if f.endswith(ignored_file))))\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        files.extend(\n",
    "            file\n",
    "        )\n",
    "\n",
    "    print(files)\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        results = []\n",
    "        with tqdm(total=len(files), desc='Loading new documents', ncols=80) as pbar:\n",
    "            for i, docs in enumerate(pool.imap_unordered(load_single_document, files)):\n",
    "                results.extend(docs)\n",
    "                pbar.update()\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_documents(ignored_files: List[str] = []) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load documents and split in chunks\n",
    "    \"\"\"\n",
    "    print(f\"Loading documents from {source_directory}\")\n",
    "\n",
    "    documents = load_documents(source_directory, ignored_files)\n",
    "    if not documents:\n",
    "        print(\"No new documents to load\")\n",
    "        exit(0)\n",
    "    print(f\"Loaded {len(documents)} new documents from {source_directory}\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} tokens each)\")\n",
    "    return texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.gemini import Gemini\n",
    "from embedders.gemini import GeminiEmbedder\n",
    "from embedchain.config import BaseLlmConfig\n",
    "from embedchain.config.embedder.google import GoogleAIEmbedderConfig\n",
    "from chromadb.config import Settings\n",
    "from vectordb.chroma import ChromaDB\n",
    "import mosanid.prompts as prompts\n",
    "\n",
    "import os\n",
    "\n",
    "MODEL = \"gemini-1.5-pro\"\n",
    "EMBEDDER = \"models/text-embedding-004\"\n",
    "\n",
    "config = BaseLlmConfig()\n",
    "config.model = MODEL\n",
    "config.api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "config.system_prompt = prompts.DOCS_SITE_DEFAULT_PROMPT\n",
    "model = Gemini(config)\n",
    "\n",
    "config = GoogleAIEmbedderConfig(model=EMBEDDER)\n",
    "embedder = GeminiEmbedder(config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['docs\\\\alex-rosenberg discrete mathematics5.pdf', 'docs\\\\relations.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents:   0%|                              | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "embeddings = load_documents('docs')\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['docs\\\\relations.pdf', 'docs\\\\relations.pptx']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents:   0%|                              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "CHROMA_SETTINGS = Settings(\n",
    "        persist_directory='db',\n",
    "        anonymized_telemetry=False\n",
    ")\n",
    "CHROMA_SETTINGS.is_persistent = True\n",
    "os.environ[\"EC_TELEMETRY\"] = \"false\"\n",
    "\n",
    "chroma = ChromaDB(embedder, CHROMA_SETTINGS)\n",
    "\n",
    "collection = chroma._get_or_create_collection('mosanid-model')\n",
    "embeddings = load_documents('docs', ['alex-rosenberg discrete mathematics5.pdf', 'relations.pptx'])\n",
    "embeddings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
